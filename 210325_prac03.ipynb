{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210325_prac03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i33z4PFj7SPF"
      },
      "source": [
        "\\[SEP592\\] 소프트웨어 특강 <데이터사이언스 입문>\n",
        "# 4주차 실습 파트\n",
        "\n",
        "> 강의일: 2021.03.25.\n",
        "\n",
        "👤 실습담당자: 임채균 (KAIST 전산학부) &nbsp;&nbsp; | &nbsp;&nbsp; 📧 Email: rayote@kaist.ac.kr\n",
        "\n",
        "---\n",
        "<br />\n",
        "\n",
        "#### &nbsp;&nbsp; *실습 목표*\n",
        "\n",
        "*   사전학습된 VGG 모델을 Keras에서 사용하는 방법을 확인함.\n",
        "*   Keras 환경에서 <u>RNN (Recurrent Neural Network)의 구조 및 사용법</u>을 학습함.\n",
        "\n",
        "\n",
        "\n",
        "<br />\n",
        "\n",
        "#### &nbsp;&nbsp; *References*\n",
        "\n",
        "*   김태영, “블록과 함께 하는 파이썬 딥러닝 케라스,” 디지털\n",
        "북스, 2017.\n",
        "  * 김태영의 케라스 블로그 <small>https://tykimos.github.io/lecture/</small>\n",
        "\n",
        "<br />\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arW3XP-uLgkx"
      },
      "source": [
        "##### *(참고)* 각각의 코드 셀의 실행시간을 자동으로 측정해주는 모듈을 설치함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKkgeDyuLktL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce29ed54-aad6-4b74-eb77-dfe6a1adbde0"
      },
      "source": [
        "# 각 코드 셀의 실행시간 측정 모듈\n",
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (54.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "time: 136 µs (started: 2021-03-27 08:58:02 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzrYGRK2ixFg"
      },
      "source": [
        "##### Keras 버전 차이로 실습 시 에러 발생하므로, 구버전으로 재설치\n",
        "\n",
        "*   재설치 버전 \n",
        "    - keras 2.3.1\n",
        "    -   tensorflow 2.2.0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAzsOyiziwxB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db1e41c9-e749-4567-b7aa-b4e7019fa1fc"
      },
      "source": [
        "# 기존 keras 삭제하기\n",
        "!pip uninstall -y keras\n",
        "!pip uninstall -y tensorflow\n",
        "\n",
        "# 구버전 재설치\n",
        "!pip install keras==2.3.1\n",
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-2.3.1:\n",
            "  Successfully uninstalled Keras-2.3.1\n",
            "Uninstalling tensorflow-2.2.0:\n",
            "  Successfully uninstalled tensorflow-2.2.0\n",
            "Collecting keras==2.3.1\n",
            "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.2.0\n",
            "  Using cached https://files.pythonhosted.org/packages/4c/1a/0d79814736cfecc825ab8094b39648cc9c46af7af1bae839928acb73b4dd/tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.36.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (2.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (54.1.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 1min 13s (started: 2021-03-27 08:52:10 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZByadnfjafF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b10df30-5f9a-4783-bdcf-a54c87944e67"
      },
      "source": [
        "import keras\n",
        "print(keras.__version__)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.3.1\n",
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVRPshpP4Nhq"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH--H1yJOPXv"
      },
      "source": [
        "## **<small>(지난 실습 cont'd)</small> 5. 사전학습된 VGG 모델 사용**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmM7bAS6O6tX"
      },
      "source": [
        "### **도전 시험셋 데이터 준비**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGxfL1OiO5ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a5c6fb-ef5f-4220-fc74-da525124676f"
      },
      "source": [
        "# Colab 환경에 데이터 받기\n",
        "!wget https://github.com/tykimos/tykimos.github.io/raw/master/warehouse/2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-27 08:53:50--  https://github.com/tykimos/tykimos.github.io/raw/master/warehouse/2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/tykimos/tykimos.github.io/master/warehouse/2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip [following]\n",
            "--2021-03-27 08:53:50--  https://raw.githubusercontent.com/tykimos/tykimos.github.io/master/warehouse/2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335762 (328K) [application/zip]\n",
            "Saving to: ‘2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip.1’\n",
            "\n",
            "\r          2017-3-8-   0%[                    ]       0  --.-KB/s               \r2017-3-8-CNN_Data_A 100%[===================>] 327.89K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-03-27 08:53:50 (17.9 MB/s) - ‘2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip.1’ saved [335762/335762]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoFzZll75nG7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMp-43YnO5a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5a9b4a-111f-4b5e-bbd7-33c1cc5a121b"
      },
      "source": [
        "# 데이터 경로(warehouse/)에 압축 해제하기\n",
        "!unzip 2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip -d warehouse"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip\n",
            "replace warehouse/hard_handwriting_shape/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: warehouse/hard_handwriting_shape/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/circle/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/circle/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/circle/circle021.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/circle/._circle021.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/circle/circle022.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/circle/._circle022.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/circle/circle023.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/circle/._circle023.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/circle/circle024.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/circle/._circle024.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/circle/circle025.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/circle/._circle025.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/rectangle/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/rectangle/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/rectangle/rectangle021.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/rectangle/._rectangle021.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/rectangle/rectangle022.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/rectangle/._rectangle022.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/rectangle/rectangle023.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/rectangle/._rectangle023.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/rectangle/rectangle024.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/rectangle/._rectangle024.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/rectangle/rectangle025.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/rectangle/._rectangle025.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/triangle/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/triangle/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/triangle/triangle021.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/triangle/._triangle021.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/triangle/triangle022.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/triangle/._triangle022.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/triangle/triangle023.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/triangle/._triangle023.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/triangle/triangle024.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/triangle/._triangle024.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/test/triangle/triangle025.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/test/triangle/._triangle025.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle001.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle001.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle002.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle002.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle003.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle003.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle004.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle004.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle005.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle005.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle006.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle006.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle007.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle007.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle008.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle008.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle009.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle009.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle010.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle010.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle011.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle011.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle012.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle012.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle013.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle013.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle014.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle014.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/circle/circle015.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/circle/._circle015.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle001.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle001.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle002.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle002.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle003.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle003.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle004.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle004.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle005.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle005.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle006.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle006.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle007.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle007.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle008.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle008.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle009.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle009.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle010.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle010.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle011.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle011.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle012.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle012.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle013.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle013.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle014.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle014.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/rectangle/rectangle015.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/rectangle/._rectangle015.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/.DS_Store  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._.DS_Store  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle001.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle001.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle002.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle002.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle003.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle003.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle004.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle004.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle005.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle005.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle006.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle006.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle007.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle007.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle008.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle008.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle009.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle009.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle010.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle010.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle011.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle011.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle012.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle012.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle013.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle013.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle014.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle014.png  \n",
            "  inflating: warehouse/hard_handwriting_shape/train/triangle/triangle015.png  \n",
            "  inflating: warehouse/__MACOSX/hard_handwriting_shape/train/triangle/._triangle015.png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOx9A74M5wfY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smyStQBQRpaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e468577-1adb-4ee3-a781-a9f5ebb11b28"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 랜덤시드 고정시키기\n",
        "np.random.seed(3)\n",
        "\n",
        "# 데이터 생성하기\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'warehouse/hard_handwriting_shape/train',\n",
        "        target_size=(224, 224),   # VGG는 이미지를 224×224 크기 사용\n",
        "        batch_size=3,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'warehouse/hard_handwriting_shape/test',\n",
        "        target_size=(224, 224),   # VGG는 이미지를 224×224 크기 사용\n",
        "        batch_size=3,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 45 images belonging to 3 classes.\n",
            "Found 15 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToB1sCtdOPXw"
      },
      "source": [
        "### **VGG-16 모델**\n",
        "\n",
        "*참조 레퍼런스*\n",
        "\n",
        "https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n",
        "\n",
        "<br />\n",
        "\n",
        "**주요 파라미터**\n",
        "\n",
        "*   `include_top (True)`: \n",
        "  - Whether or not to include the output layers for the model. You don’t need these if you are fitting the model on your own problem.\n",
        "*   `weights ('imagenet')`: \n",
        "  - What weights to load. You can specify None to not load pre-trained weights if you are interested in training the model yourself from scratch.\n",
        "*   `input_tensor (None)`: \n",
        "  - A new input layer if you intend to fit the model on new data of a different size.\n",
        "*   `input_shape (None)`: \n",
        "  - The size of images that the model is expected to take if you change the input layer.\n",
        "*   `pooling (None)`: \n",
        "  - The type of pooling to use when you are training a new set of output layers.\n",
        "*   `classes (1000)`: \n",
        "  - The number of classes (e.g. size of output vector) for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLW6XGNvOPXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a91822e-2203-46b4-a187-7e244da57a2c"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 11s 0us/step\n",
            "time: 13.6 s (started: 2021-03-27 08:58:12 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lrc6RAgOPXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a75db7b7-88e2-4d73-b367-ecc2d79b2e0e"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"1829pt\" viewBox=\"0.00 0.00 400.00 1881.00\" width=\"389pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.9722 .9722) rotate(0) translate(4 1877)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1877 396,-1877 396,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139919735391888 -->\n<g class=\"node\" id=\"node1\">\n<title>139919735391888</title>\n<polygon fill=\"none\" points=\"34.5,-1826.5 34.5,-1872.5 357.5,-1872.5 357.5,-1826.5 34.5,-1826.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-1845.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"167.5,-1826.5 167.5,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.5\" y=\"-1857.3\">input:</text>\n<polyline fill=\"none\" points=\"167.5,-1849.5 225.5,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.5\" y=\"-1834.3\">output:</text>\n<polyline fill=\"none\" points=\"225.5,-1826.5 225.5,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.5\" y=\"-1857.3\">(None, 224, 224, 3)</text>\n<polyline fill=\"none\" points=\"225.5,-1849.5 357.5,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.5\" y=\"-1834.3\">(None, 224, 224, 3)</text>\n</g>\n<!-- 139919743216336 -->\n<g class=\"node\" id=\"node2\">\n<title>139919743216336</title>\n<polygon fill=\"none\" points=\"18,-1743.5 18,-1789.5 374,-1789.5 374,-1743.5 18,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-1762.8\">block1_conv1: Conv2D</text>\n<polyline fill=\"none\" points=\"176,-1743.5 176,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"176,-1766.5 234,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"234,-1743.5 234,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1774.3\">(None, 224, 224, 3)</text>\n<polyline fill=\"none\" points=\"234,-1766.5 374,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1751.3\">(None, 224, 224, 64)</text>\n</g>\n<!-- 139919735391888&#45;&gt;139919743216336 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139919735391888-&gt;139919743216336</title>\n<path d=\"M196,-1826.3799C196,-1818.1745 196,-1808.7679 196,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1799.784 196,-1789.784 192.5001,-1799.784 199.5001,-1799.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919897057552 -->\n<g class=\"node\" id=\"node3\">\n<title>139919897057552</title>\n<polygon fill=\"none\" points=\"18,-1660.5 18,-1706.5 374,-1706.5 374,-1660.5 18,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-1679.8\">block1_conv2: Conv2D</text>\n<polyline fill=\"none\" points=\"176,-1660.5 176,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"176,-1683.5 234,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"234,-1660.5 234,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1691.3\">(None, 224, 224, 64)</text>\n<polyline fill=\"none\" points=\"234,-1683.5 374,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1668.3\">(None, 224, 224, 64)</text>\n</g>\n<!-- 139919743216336&#45;&gt;139919897057552 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139919743216336-&gt;139919897057552</title>\n<path d=\"M196,-1743.3799C196,-1735.1745 196,-1725.7679 196,-1716.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1716.784 196,-1706.784 192.5001,-1716.784 199.5001,-1716.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139921312222672 -->\n<g class=\"node\" id=\"node4\">\n<title>139921312222672</title>\n<polygon fill=\"none\" points=\"3,-1577.5 3,-1623.5 389,-1623.5 389,-1577.5 3,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-1596.8\">block1_pool: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"191,-1577.5 191,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"220\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"191,-1600.5 249,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"220\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"249,-1577.5 249,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-1608.3\">(None, 224, 224, 64)</text>\n<polyline fill=\"none\" points=\"249,-1600.5 389,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-1585.3\">(None, 112, 112, 64)</text>\n</g>\n<!-- 139919897057552&#45;&gt;139921312222672 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139919897057552-&gt;139921312222672</title>\n<path d=\"M196,-1660.3799C196,-1652.1745 196,-1642.7679 196,-1633.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1633.784 196,-1623.784 192.5001,-1633.784 199.5001,-1633.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735653008 -->\n<g class=\"node\" id=\"node5\">\n<title>139919735653008</title>\n<polygon fill=\"none\" points=\"15,-1494.5 15,-1540.5 377,-1540.5 377,-1494.5 15,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-1513.8\">block2_conv1: Conv2D</text>\n<polyline fill=\"none\" points=\"173,-1494.5 173,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"173,-1517.5 231,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"231,-1494.5 231,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1525.3\">(None, 112, 112, 64)</text>\n<polyline fill=\"none\" points=\"231,-1517.5 377,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1502.3\">(None, 112, 112, 128)</text>\n</g>\n<!-- 139921312222672&#45;&gt;139919735653008 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139921312222672-&gt;139919735653008</title>\n<path d=\"M196,-1577.3799C196,-1569.1745 196,-1559.7679 196,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1550.784 196,-1540.784 192.5001,-1550.784 199.5001,-1550.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735457872 -->\n<g class=\"node\" id=\"node6\">\n<title>139919735457872</title>\n<polygon fill=\"none\" points=\"15,-1411.5 15,-1457.5 377,-1457.5 377,-1411.5 15,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-1430.8\">block2_conv2: Conv2D</text>\n<polyline fill=\"none\" points=\"173,-1411.5 173,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"173,-1434.5 231,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"231,-1411.5 231,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1442.3\">(None, 112, 112, 128)</text>\n<polyline fill=\"none\" points=\"231,-1434.5 377,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1419.3\">(None, 112, 112, 128)</text>\n</g>\n<!-- 139919735653008&#45;&gt;139919735457872 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139919735653008-&gt;139919735457872</title>\n<path d=\"M196,-1494.3799C196,-1486.1745 196,-1476.7679 196,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1467.784 196,-1457.784 192.5001,-1467.784 199.5001,-1467.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735397008 -->\n<g class=\"node\" id=\"node7\">\n<title>139919735397008</title>\n<polygon fill=\"none\" points=\"0,-1328.5 0,-1374.5 392,-1374.5 392,-1328.5 0,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-1347.8\">block2_pool: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"188,-1328.5 188,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"188,-1351.5 246,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"246,-1328.5 246,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-1359.3\">(None, 112, 112, 128)</text>\n<polyline fill=\"none\" points=\"246,-1351.5 392,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-1336.3\">(None, 56, 56, 128)</text>\n</g>\n<!-- 139919735457872&#45;&gt;139919735397008 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139919735457872-&gt;139919735397008</title>\n<path d=\"M196,-1411.3799C196,-1403.1745 196,-1393.7679 196,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1384.784 196,-1374.784 192.5001,-1384.784 199.5001,-1384.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735397456 -->\n<g class=\"node\" id=\"node8\">\n<title>139919735397456</title>\n<polygon fill=\"none\" points=\"22,-1245.5 22,-1291.5 370,-1291.5 370,-1245.5 22,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-1264.8\">block3_conv1: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-1245.5 180,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-1268.5 238,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-1245.5 238,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1276.3\">(None, 56, 56, 128)</text>\n<polyline fill=\"none\" points=\"238,-1268.5 370,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1253.3\">(None, 56, 56, 256)</text>\n</g>\n<!-- 139919735397008&#45;&gt;139919735397456 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139919735397008-&gt;139919735397456</title>\n<path d=\"M196,-1328.3799C196,-1320.1745 196,-1310.7679 196,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1301.784 196,-1291.784 192.5001,-1301.784 199.5001,-1301.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735423248 -->\n<g class=\"node\" id=\"node9\">\n<title>139919735423248</title>\n<polygon fill=\"none\" points=\"22,-1162.5 22,-1208.5 370,-1208.5 370,-1162.5 22,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-1181.8\">block3_conv2: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-1162.5 180,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-1185.5 238,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-1162.5 238,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1193.3\">(None, 56, 56, 256)</text>\n<polyline fill=\"none\" points=\"238,-1185.5 370,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1170.3\">(None, 56, 56, 256)</text>\n</g>\n<!-- 139919735397456&#45;&gt;139919735423248 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139919735397456-&gt;139919735423248</title>\n<path d=\"M196,-1245.3799C196,-1237.1745 196,-1227.7679 196,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1218.784 196,-1208.784 192.5001,-1218.784 199.5001,-1218.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735433616 -->\n<g class=\"node\" id=\"node10\">\n<title>139919735433616</title>\n<polygon fill=\"none\" points=\"22,-1079.5 22,-1125.5 370,-1125.5 370,-1079.5 22,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-1098.8\">block3_conv3: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-1079.5 180,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-1102.5 238,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-1079.5 238,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1110.3\">(None, 56, 56, 256)</text>\n<polyline fill=\"none\" points=\"238,-1102.5 370,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-1087.3\">(None, 56, 56, 256)</text>\n</g>\n<!-- 139919735423248&#45;&gt;139919735433616 -->\n<g class=\"edge\" id=\"edge9\">\n<title>139919735423248-&gt;139919735433616</title>\n<path d=\"M196,-1162.3799C196,-1154.1745 196,-1144.7679 196,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1135.784 196,-1125.784 192.5001,-1135.784 199.5001,-1135.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735395920 -->\n<g class=\"node\" id=\"node11\">\n<title>139919735395920</title>\n<polygon fill=\"none\" points=\"7,-996.5 7,-1042.5 385,-1042.5 385,-996.5 7,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-1015.8\">block3_pool: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"195,-996.5 195,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"195,-1019.5 253,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"253,-996.5 253,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-1027.3\">(None, 56, 56, 256)</text>\n<polyline fill=\"none\" points=\"253,-1019.5 385,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-1004.3\">(None, 28, 28, 256)</text>\n</g>\n<!-- 139919735433616&#45;&gt;139919735395920 -->\n<g class=\"edge\" id=\"edge10\">\n<title>139919735433616-&gt;139919735395920</title>\n<path d=\"M196,-1079.3799C196,-1071.1745 196,-1061.7679 196,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-1052.784 196,-1042.784 192.5001,-1052.784 199.5001,-1052.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735386576 -->\n<g class=\"node\" id=\"node12\">\n<title>139919735386576</title>\n<polygon fill=\"none\" points=\"22,-913.5 22,-959.5 370,-959.5 370,-913.5 22,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-932.8\">block4_conv1: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-913.5 180,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-936.5 238,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-913.5 238,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-944.3\">(None, 28, 28, 256)</text>\n<polyline fill=\"none\" points=\"238,-936.5 370,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-921.3\">(None, 28, 28, 512)</text>\n</g>\n<!-- 139919735395920&#45;&gt;139919735386576 -->\n<g class=\"edge\" id=\"edge11\">\n<title>139919735395920-&gt;139919735386576</title>\n<path d=\"M196,-996.3799C196,-988.1745 196,-978.7679 196,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-969.784 196,-959.784 192.5001,-969.784 199.5001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919734913168 -->\n<g class=\"node\" id=\"node13\">\n<title>139919734913168</title>\n<polygon fill=\"none\" points=\"22,-830.5 22,-876.5 370,-876.5 370,-830.5 22,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-849.8\">block4_conv2: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-830.5 180,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-853.5 238,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-830.5 238,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-861.3\">(None, 28, 28, 512)</text>\n<polyline fill=\"none\" points=\"238,-853.5 370,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-838.3\">(None, 28, 28, 512)</text>\n</g>\n<!-- 139919735386576&#45;&gt;139919734913168 -->\n<g class=\"edge\" id=\"edge12\">\n<title>139919735386576-&gt;139919734913168</title>\n<path d=\"M196,-913.3799C196,-905.1745 196,-895.7679 196,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-886.784 196,-876.784 192.5001,-886.784 199.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735139984 -->\n<g class=\"node\" id=\"node14\">\n<title>139919735139984</title>\n<polygon fill=\"none\" points=\"22,-747.5 22,-793.5 370,-793.5 370,-747.5 22,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-766.8\">block4_conv3: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-747.5 180,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-770.5 238,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-747.5 238,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-778.3\">(None, 28, 28, 512)</text>\n<polyline fill=\"none\" points=\"238,-770.5 370,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-755.3\">(None, 28, 28, 512)</text>\n</g>\n<!-- 139919734913168&#45;&gt;139919735139984 -->\n<g class=\"edge\" id=\"edge13\">\n<title>139919734913168-&gt;139919735139984</title>\n<path d=\"M196,-830.3799C196,-822.1745 196,-812.7679 196,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-803.784 196,-793.784 192.5001,-803.784 199.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735139920 -->\n<g class=\"node\" id=\"node15\">\n<title>139919735139920</title>\n<polygon fill=\"none\" points=\"7,-664.5 7,-710.5 385,-710.5 385,-664.5 7,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-683.8\">block4_pool: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"195,-664.5 195,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"195,-687.5 253,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"253,-664.5 253,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-695.3\">(None, 28, 28, 512)</text>\n<polyline fill=\"none\" points=\"253,-687.5 385,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-672.3\">(None, 14, 14, 512)</text>\n</g>\n<!-- 139919735139984&#45;&gt;139919735139920 -->\n<g class=\"edge\" id=\"edge14\">\n<title>139919735139984-&gt;139919735139920</title>\n<path d=\"M196,-747.3799C196,-739.1745 196,-729.7679 196,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-720.784 196,-710.784 192.5001,-720.784 199.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735155088 -->\n<g class=\"node\" id=\"node16\">\n<title>139919735155088</title>\n<polygon fill=\"none\" points=\"22,-581.5 22,-627.5 370,-627.5 370,-581.5 22,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-600.8\">block5_conv1: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-581.5 180,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-604.5 238,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-581.5 238,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-612.3\">(None, 14, 14, 512)</text>\n<polyline fill=\"none\" points=\"238,-604.5 370,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-589.3\">(None, 14, 14, 512)</text>\n</g>\n<!-- 139919735139920&#45;&gt;139919735155088 -->\n<g class=\"edge\" id=\"edge15\">\n<title>139919735139920-&gt;139919735155088</title>\n<path d=\"M196,-664.3799C196,-656.1745 196,-646.7679 196,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-637.784 196,-627.784 192.5001,-637.784 199.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735172880 -->\n<g class=\"node\" id=\"node17\">\n<title>139919735172880</title>\n<polygon fill=\"none\" points=\"22,-498.5 22,-544.5 370,-544.5 370,-498.5 22,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-517.8\">block5_conv2: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-498.5 180,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-521.5 238,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-498.5 238,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-529.3\">(None, 14, 14, 512)</text>\n<polyline fill=\"none\" points=\"238,-521.5 370,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-506.3\">(None, 14, 14, 512)</text>\n</g>\n<!-- 139919735155088&#45;&gt;139919735172880 -->\n<g class=\"edge\" id=\"edge16\">\n<title>139919735155088-&gt;139919735172880</title>\n<path d=\"M196,-581.3799C196,-573.1745 196,-563.7679 196,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-554.784 196,-544.784 192.5001,-554.784 199.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735156304 -->\n<g class=\"node\" id=\"node18\">\n<title>139919735156304</title>\n<polygon fill=\"none\" points=\"22,-415.5 22,-461.5 370,-461.5 370,-415.5 22,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-434.8\">block5_conv3: Conv2D</text>\n<polyline fill=\"none\" points=\"180,-415.5 180,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"180,-438.5 238,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"238,-415.5 238,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-446.3\">(None, 14, 14, 512)</text>\n<polyline fill=\"none\" points=\"238,-438.5 370,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304\" y=\"-423.3\">(None, 14, 14, 512)</text>\n</g>\n<!-- 139919735172880&#45;&gt;139919735156304 -->\n<g class=\"edge\" id=\"edge17\">\n<title>139919735172880-&gt;139919735156304</title>\n<path d=\"M196,-498.3799C196,-490.1745 196,-480.7679 196,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-471.784 196,-461.784 192.5001,-471.784 199.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735211664 -->\n<g class=\"node\" id=\"node19\">\n<title>139919735211664</title>\n<polygon fill=\"none\" points=\"7,-332.5 7,-378.5 385,-378.5 385,-332.5 7,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101\" y=\"-351.8\">block5_pool: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"195,-332.5 195,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"195,-355.5 253,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"253,-332.5 253,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-363.3\">(None, 14, 14, 512)</text>\n<polyline fill=\"none\" points=\"253,-355.5 385,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"319\" y=\"-340.3\">(None, 7, 7, 512)</text>\n</g>\n<!-- 139919735156304&#45;&gt;139919735211664 -->\n<g class=\"edge\" id=\"edge18\">\n<title>139919735156304-&gt;139919735211664</title>\n<path d=\"M196,-415.3799C196,-407.1745 196,-397.7679 196,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-388.784 196,-378.784 192.5001,-388.784 199.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735231824 -->\n<g class=\"node\" id=\"node20\">\n<title>139919735231824</title>\n<polygon fill=\"none\" points=\"59.5,-249.5 59.5,-295.5 332.5,-295.5 332.5,-249.5 59.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-268.8\">flatten: Flatten</text>\n<polyline fill=\"none\" points=\"157.5,-249.5 157.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"157.5,-272.5 215.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"215.5,-249.5 215.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274\" y=\"-280.3\">(None, 7, 7, 512)</text>\n<polyline fill=\"none\" points=\"215.5,-272.5 332.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274\" y=\"-257.3\">(None, 25088)</text>\n</g>\n<!-- 139919735211664&#45;&gt;139919735231824 -->\n<g class=\"edge\" id=\"edge19\">\n<title>139919735211664-&gt;139919735231824</title>\n<path d=\"M196,-332.3799C196,-324.1745 196,-314.7679 196,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-305.784 196,-295.784 192.5001,-305.784 199.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735231184 -->\n<g class=\"node\" id=\"node21\">\n<title>139919735231184</title>\n<polygon fill=\"none\" points=\"77.5,-166.5 77.5,-212.5 314.5,-212.5 314.5,-166.5 77.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116\" y=\"-185.8\">fc1: Dense</text>\n<polyline fill=\"none\" points=\"154.5,-166.5 154.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"154.5,-189.5 212.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"212.5,-166.5 212.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-197.3\">(None, 25088)</text>\n<polyline fill=\"none\" points=\"212.5,-189.5 314.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-174.3\">(None, 4096)</text>\n</g>\n<!-- 139919735231824&#45;&gt;139919735231184 -->\n<g class=\"edge\" id=\"edge20\">\n<title>139919735231824-&gt;139919735231184</title>\n<path d=\"M196,-249.3799C196,-241.1745 196,-231.7679 196,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-222.784 196,-212.784 192.5001,-222.784 199.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735232464 -->\n<g class=\"node\" id=\"node22\">\n<title>139919735232464</title>\n<polygon fill=\"none\" points=\"81,-83.5 81,-129.5 311,-129.5 311,-83.5 81,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"119.5\" y=\"-102.8\">fc2: Dense</text>\n<polyline fill=\"none\" points=\"158,-83.5 158,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"158,-106.5 216,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"216,-83.5 216,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-114.3\">(None, 4096)</text>\n<polyline fill=\"none\" points=\"216,-106.5 311,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-91.3\">(None, 4096)</text>\n</g>\n<!-- 139919735231184&#45;&gt;139919735232464 -->\n<g class=\"edge\" id=\"edge21\">\n<title>139919735231184-&gt;139919735232464</title>\n<path d=\"M196,-166.3799C196,-158.1745 196,-148.7679 196,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-139.784 196,-129.784 192.5001,-139.784 199.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139919735311056 -->\n<g class=\"node\" id=\"node23\">\n<title>139919735311056</title>\n<polygon fill=\"none\" points=\"58.5,-.5 58.5,-46.5 333.5,-46.5 333.5,-.5 58.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"119.5\" y=\"-19.8\">predictions: Dense</text>\n<polyline fill=\"none\" points=\"180.5,-.5 180.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"180.5,-23.5 238.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"238.5,-.5 238.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-31.3\">(None, 4096)</text>\n<polyline fill=\"none\" points=\"238.5,-23.5 333.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-8.3\">(None, 1000)</text>\n</g>\n<!-- 139919735232464&#45;&gt;139919735311056 -->\n<g class=\"edge\" id=\"edge22\">\n<title>139919735232464-&gt;139919735311056</title>\n<path d=\"M196,-83.3799C196,-75.1745 196,-65.7679 196,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"199.5001,-56.784 196,-46.784 192.5001,-56.784 199.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "text": [
            "time: 434 ms (started: 2021-03-27 08:59:02 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-fH0exVOPXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6348e2d5-ade9-49f1-d6da-7910929d7ff2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "time: 4.44 ms (started: 2021-03-27 08:59:31 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l7pvxzDOPX0"
      },
      "source": [
        "##### *입력 이미지 데이터 준비*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n-43mHPOPX0"
      },
      "source": [
        "VGG 모델에서는 입력 이미지를 224×224 크기로 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yl9yoJdOPX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6444dd5b-5a78-45db-a5e6-137ef758cba6"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "# load an image from file\n",
        "path_img = 'warehouse/hard_handwriting_shape/train/triangle/triangle001.png'\n",
        "image = load_img(path_img, target_size=(224, 224))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 28.7 ms (started: 2021-03-27 08:59:41 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGTuU0JXOPX2"
      },
      "source": [
        "`Numpy` 배열로 변경하고, 기존 VGG 모델에 맞도록 추가 dimension을 포함하도록 `reshape()` 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPXUdbHqOPX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407c96ea-f9fe-401c-ab7a-139810ae9f0a"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.93 ms (started: 2021-03-27 09:00:45 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV1RurawOPX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623ab209-9a42-4f79-e406-aeee78a566d6"
      },
      "source": [
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.26 ms (started: 2021-03-27 09:00:47 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZtpMc4MOPX2"
      },
      "source": [
        "Keras에서 제공하는 VGG모델의 입력 전처리 함수 `preprocess_input()`을 적용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWDo05EaOPX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da3a1f6-ee41-45be-a4bd-ed55b2166021"
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.96 ms (started: 2021-03-27 09:01:02 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvHrJWJP6qLR",
        "outputId": "ecf0e4e1-c7e7-4a07-8f45-992391db97be"
      },
      "source": [
        "image"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         ...,\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ]],\n",
              "\n",
              "        [[151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         ...,\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ]],\n",
              "\n",
              "        [[151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         ...,\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         ...,\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ]],\n",
              "\n",
              "        [[151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         ...,\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ]],\n",
              "\n",
              "        [[151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         ...,\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ],\n",
              "         [151.061  , 138.22101, 131.32   ]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "text": [
            "time: 12.8 ms (started: 2021-03-27 09:01:27 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWr0alTAOPX3"
      },
      "source": [
        "##### *모델을 사용하여 예측 실행*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44-P-Ug-OPX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629a614a-ad49-45c6-a45f-47d4f0370680"
      },
      "source": [
        "# predict the probability across all output classes\n",
        "yhat = model.predict(image)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 6.07 s (started: 2021-03-27 09:01:08 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZYEOT6FOPX3"
      },
      "source": [
        "##### *예측결과 해석*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozwa-GZ9OPX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc82107-8721-4b64-e00f-e3d2c391334d"
      },
      "source": [
        "from keras.applications.vgg16 import decode_predictions\n",
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(yhat)\n",
        "# retrieve the most likely result, e.g. highest probability\n",
        "label = label[0][0]\n",
        "# print the classification\n",
        "print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "airship (6.42%)\n",
            "time: 145 ms (started: 2021-03-27 09:02:47 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4_oekJQOPX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "325eb2dc-fc1c-4fbd-8d67-2489fc48b1b2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(image.reshape(224, 224, 3))\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 187 ms (started: 2021-03-27 09:04:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUxIfJxpOPX4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYSK9RBxOPX4"
      },
      "source": [
        "#### *전체 코드 재정리 (함수화)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRZbiUsIOPX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6c1d60-deb4-4426-b026-2c5f877acfd8"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# 입력 전처리 함수\n",
        "def preproc_image_vgg(path_img):\n",
        "  # load an image from file\n",
        "  image = load_img(path_img, target_size=(224, 224))\n",
        "\n",
        "  # convert the image pixels to a numpy array\n",
        "  image = img_to_array(image)\n",
        "\n",
        "  # reshape data for the model\n",
        "  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "  # prepare the image for the VGG model\n",
        "  image = preprocess_input(image)\n",
        "\n",
        "  return image"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.18 ms (started: 2021-03-27 09:05:20 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NemXwwi7OPX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eff3b85-391d-4f51-cd24-600a77c7ffd2"
      },
      "source": [
        "from keras.applications.vgg16 import decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 결과 해석 및 출력 함수\n",
        "def print_result_vgg(yhat, image):\n",
        "  # convert the probabilities to class labels\n",
        "  label = decode_predictions(yhat)\n",
        "  # retrieve the most likely result, e.g. highest probability\n",
        "  label = label[0][0]\n",
        "  # print the classification\n",
        "  print('> Predicted Label=  %s (%.2f%%)' % (label[1], label[2]*100))\n",
        "\n",
        "  # show an image\n",
        "  plt.imshow(image.reshape(224, 224, 3))\n",
        "  plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 113 ms (started: 2021-03-27 09:05:28 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd5lJfJ9OPX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e03755-c335-4068-b56c-0dda1b9b9a5a"
      },
      "source": [
        "# VGG를 활용한 전체 예측과정 함수\n",
        "def predict_vgg(path_img):\n",
        "  image = preproc_image_vgg(path_img)\n",
        "\n",
        "  # predict the probability across all output classes\n",
        "  yhat = model.predict(image)\n",
        "\n",
        "  print_result_vgg(yhat, image)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.66 ms (started: 2021-03-27 09:06:20 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awOmgxpJOPX5"
      },
      "source": [
        "##### *실행결과 테스트*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz_EtDm5OPX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "ea068dde-9a52-4bd1-dcd5-f5e2e03373bf"
      },
      "source": [
        "predict_vgg('warehouse/hard_handwriting_shape/train/triangle/triangle001.png')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> Predicted Label=  airship (6.42%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 156 ms (started: 2021-03-27 09:06:37 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4vpMOKMOPX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "40a3358f-e9ce-4c54-c2b6-294bc05350af"
      },
      "source": [
        "predict_vgg('warehouse/hard_handwriting_shape/train/circle/circle001.png')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> Predicted Label=  envelope (18.01%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 160 ms (started: 2021-03-27 09:06:40 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U_CH2DROPX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "1cd2a5c7-9309-4121-9034-a3fe8430bc3f"
      },
      "source": [
        "predict_vgg('warehouse/hard_handwriting_shape/train/rectangle/rectangle001.png')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> Predicted Label=  television (25.52%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 150 ms (started: 2021-03-27 09:06:42 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnBN2PnHOoVG"
      },
      "source": [
        "### **VGG-16 모델에 대한 Fine-tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EESrCEmPNB0"
      },
      "source": [
        "#### *모델 추가 구성하기 (1) - 예측 레이어 추가*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSlqL77OPX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce8e687-faed-4abb-baac-6b40b24184d0"
      },
      "source": [
        "from keras.layers import Dense, GlobalAveragePooling1D\n",
        "from keras import Model\n",
        "\n",
        "base_model = VGG16()\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = base_model.output\n",
        "x = Dense(256, activation='relu')(x)\n",
        "\n",
        "# and a logistic layer -- let's say we have 3 classes\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.5 s (started: 2021-03-27 09:07:16 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-5DK7B04NfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a879d5e-29ce-4674-cac3-290ca3d09f2b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               256256    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 138,614,571\n",
            "Trainable params: 138,614,571\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "time: 12.9 ms (started: 2021-03-27 09:07:26 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op4QSVsl4Nca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18fe9874-a78d-49c0-e852-6b1e300ddf90"
      },
      "source": [
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 55.4 ms (started: 2021-03-27 09:07:36 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q31CqSVbOOPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "048b3f18-7595-4db6-e9b9-fc30730fbd64"
      },
      "source": [
        "# 모델 학습시키기\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=15,\n",
        "        epochs=10,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 48ms/step - loss: 1.0982 - accuracy: 0.4000 - val_loss: 1.1011 - val_accuracy: 0.5333\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 1.0912 - accuracy: 0.5778 - val_loss: 1.0860 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 1.0840 - accuracy: 0.6222 - val_loss: 1.0798 - val_accuracy: 0.4667\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 1.0760 - accuracy: 0.6222 - val_loss: 1.0858 - val_accuracy: 0.4667\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 1.0625 - accuracy: 0.6667 - val_loss: 1.0987 - val_accuracy: 0.4667\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 1.0546 - accuracy: 0.6444 - val_loss: 1.0654 - val_accuracy: 0.4667\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 1.0309 - accuracy: 0.6889 - val_loss: 1.0929 - val_accuracy: 0.4667\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 1.0103 - accuracy: 0.6667 - val_loss: 1.1182 - val_accuracy: 0.4667\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.9866 - accuracy: 0.6667 - val_loss: 0.9810 - val_accuracy: 0.4000\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.9565 - accuracy: 0.6667 - val_loss: 1.1276 - val_accuracy: 0.4667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f4128395fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.03 s (started: 2021-03-27 09:07:42 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtW6eIG2Z7oV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e2a3fa-3c36-4992-a3ed-5d280a9ef9b2"
      },
      "source": [
        "# 모델 평가하기\n",
        "print(\"-- Evaluate --\")\n",
        "scores = model.evaluate_generator(test_generator, steps=15)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Evaluate --\n",
            "accuracy: 46.67%\n",
            "time: 310 ms (started: 2021-03-27 09:09:01 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAyNolVjWt0A"
      },
      "source": [
        "#### *모델 추가 구성하기 (2) - 사전모델 일부 레이어 활용*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCUK1NI3OOKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377777bb-6fa6-4f6f-8f96-03821a8959c5"
      },
      "source": [
        "base_model2 = VGG16()\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = base_model2.output\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# and a logistic layer -- let's say we have 3 classes\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model2 = Model(inputs=base_model2.input, outputs=predictions)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.41 s (started: 2021-03-27 09:09:17 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4_4437oXNur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8343d1c-85f2-4f78-9295-2d89bbe06334"
      },
      "source": [
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# other layers\n",
        "for layer in base_model2.layers[:-2]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model2.layers[-2:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 40.1 ms (started: 2021-03-27 09:09:25 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivUAAY6rXlj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f897c62-135f-43f9-dce1-51fde62f0ce2"
      },
      "source": [
        "# 모델 학습시키기\n",
        "model2.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=15,\n",
        "        epochs=10,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 38ms/step - loss: 1.1004 - accuracy: 0.2444 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 1.0992 - accuracy: 0.3333 - val_loss: 1.1031 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 1.0998 - accuracy: 0.3333 - val_loss: 1.1047 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 1.0989 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 1.0996 - accuracy: 0.2889 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 1.0994 - accuracy: 0.2667 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 1.1003 - accuracy: 0.2444 - val_loss: 1.1021 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 1.0996 - accuracy: 0.3333 - val_loss: 1.0975 - val_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 1.1004 - accuracy: 0.3333 - val_loss: 1.1005 - val_accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 1.0992 - accuracy: 0.3333 - val_loss: 1.0972 - val_accuracy: 0.3333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f412816b410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.79 s (started: 2021-03-27 09:09:33 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QblwyY1ZZ47A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b17862-ad4e-4b06-ae4a-04fa1485fa88"
      },
      "source": [
        "# 모델 평가하기\n",
        "print(\"-- Evaluate --\")\n",
        "scores = model2.evaluate_generator(test_generator, steps=15)\n",
        "print(\"%s: %.2f%%\" %(model2.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Evaluate --\n",
            "accuracy: 33.33%\n",
            "time: 310 ms (started: 2021-03-27 09:09:59 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9Duge9tYEJv"
      },
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPzu-4Td5jJu"
      },
      "source": [
        "## **1. LSTM 모델의 기본 개념**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UX7AJp45L-7"
      },
      "source": [
        "순환 신경망 모델은 순차적인 자료에서 규칙적인 패턴을 인식하거나 그 의미를 추론할 수 있습니다. 순차적이라는 특성 때문에 간단한 레이어로도 다양한 형태의 모델을 구성할 수 있습니다. 케라스에서 제공하는 순환 신경망 레이어는 SimpleRNN, GRU, LSTM이 있으나 주로 사용하는 LSTM에 대해서 알아보겠습니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90kjNrIr5L-8"
      },
      "source": [
        "---\n",
        "\n",
        "### **긴 시퀀스를 기억할 수 있는 LSTM (Long Short-Term Memory units)  레이어**\n",
        "\n",
        "LSTM 레이어는 아래와 같이 간단히 사용할 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkk14wvl5zKM"
      },
      "source": [
        "#### *입력 형태*\n",
        "\n",
        "    LSTM(3, input_dim=1)\n",
        "\n",
        "기본 인자는 다음과 같습니다.\n",
        "* 첫번째 인자 : 메모리 셀의 개수입니다.\n",
        "* input_dim : 입력 속성 수 입니다.\n",
        "\n",
        "이는 앞서 살펴본 Dense 레이어 형태와 비슷합니다. 첫번째 인자인 메모리 셀의 개수는 기억용량 정도와 출력 형태를 결정짓습니다. Dense 레이어에서의 출력 뉴런 수와 비슷하다고 보시면 됩니다. input_dim에는 Dense 레이어와 같이 일반적으로 속성의 개수가 들어갑니다. \n",
        "\n",
        "    Dense(3, input_dim=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ctneAB52hd"
      },
      "source": [
        "LSTM의 한 가지 인자에 대해 더 알아보겠습니다.\n",
        "\n",
        "    LSTM(3, input_dim=1, input_length=4)\n",
        "\n",
        "* input_length : 시퀀스 데이터의 입력 길이\n",
        "\n",
        "Dense와 LSTM을 블록으로 도식화 하면 다음과 같습니다. 왼쪽이 Dense이고, 중앙이 input_length가 1인 LSTM이고 오른쪽이 input_length가 4인 LSTM 입니다. 사실 LSTM의 내부구조는 복잡하지만 간소화하여 외형만 표시한 것입니다. Dense 레이어와 비교한다면 히든 뉴런들이 밖으로 도출되어 있음을 보실 수 있습니다. 그리고 오른쪽 블록인 경우 input_length가 길다고 해서 각 입력마다 다른 가중치를 사용하는 것이 아니라 중앙에 있는 블록을 입력 길이 만큼 연결한 것이기 때문에 모두 동일한 가중치를 공유합니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99sP_IRG5L-9"
      },
      "source": [
        "#### *출력 형태*\n",
        "\n",
        "* return_sequences : 시퀀스 출력 여부\n",
        "\n",
        "LSTM 레이어는 return_sequences 인자에 따라 마지막 시퀀스에서 한 번만 출력할 수 있고 각 시퀀스에서 출력을 할 수 있습니다. many to many 문제를 풀거나 LSTM 레이어를 여러개로 쌓아올릴 때는 return_sequence=True 옵션을 사용합니다. 자세한 것은 뒤에서 살펴보겠습니다. 아래 그림에서 왼쪽은 return_sequences=False일 때, 오른쪽은 return_sequence=True일 때의 형상입니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXV6iIAk5L-9"
      },
      "source": [
        "#### *상태유지(stateful) 모드*\n",
        "\n",
        "* stateful : 상태 유지 여부\n",
        "\n",
        "학습 샘플의 가장 마지막 상태가 다음 샘플 학습 시에 입력으로 전달 여부를 지정하는 것입니다. 하나의 샘플은 4개의 시퀀스 입력이 있고, 총 3개의 샘플이 있을 때, 아래 그림에서 위의 블록들은 stateful=False일 때의 형상이고, 아래 블록들은 stateful=True일 때의 형상입니다. 도출된 현재 상태의 가중치가 다음 샘플 학습 시의 초기 상태로 입력됨을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58slSSad5L--"
      },
      "source": [
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fEo9Fzj5L--"
      },
      "source": [
        "---\n",
        "\n",
        "### 요약\n",
        "\n",
        "순환 신경망 레이어 중 LSTM 레이어에 대해서 알아봤습니다. 사용법은 Dense 레이어와 비슷하지만 시퀀스 출력 여부와 상태유지 모드 설정으로 다양한 형태의 신경망을 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1-lXkpD6hR-"
      },
      "source": [
        "## **2. LSTM 모델 시작하기**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGrPESdk6DpL"
      },
      "source": [
        "본 강좌에서는 간단한 순환 신경망 모델을 만들어봅니다. 늘 그렇듯이 다음과 같은 순서로 진행하겠습니다.\n",
        "\n",
        "1. 문제 정의하기\n",
        "1. 데이터셋 준비하기\n",
        "1. 모델 구성하기\n",
        "1. 모델 엮기\n",
        "1. 모델 학습시키기\n",
        "1. 모델 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7SMvf8A7jQ8"
      },
      "source": [
        "### *모듈 임포트*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRsLnl_W6DpL"
      },
      "source": [
        "import matplotlib.pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cagrMse06DpM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import theano\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG9uEdX76DpN"
      },
      "source": [
        "### *데이터 생성*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qde4RIx6DpN"
      },
      "source": [
        "dataset = np.cos(np.arange(1000)*(20*np.pi/1000))[:,None]\n",
        "\n",
        "plt.plot(dataset)\n",
        "\n",
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gbnOHLnl6DpN"
      },
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back):\n",
        "        dataX.append(dataset[i:(i+look_back), 0])\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return np.array(dataX), np.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEfy83UZ6DpO"
      },
      "source": [
        "### *학습/테스트 데이터 준비 (Window of 20 time steps)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BeNCecKJCjh"
      },
      "source": [
        "`look_back`에 지정된 `20`개 만큼의 이전 값을 보고, 그 다음 `1`개를 예측하기 위함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vK752u966DpO"
      },
      "source": [
        "look_back = 20\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf9JSC6pJW6L"
      },
      "source": [
        "`train`에 포함된 데이터 전체 개수는 `670`개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi9x-URU6DpO"
      },
      "source": [
        "print(train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8D4zW2MJddu"
      },
      "source": [
        "그 중에서, 학습데이터 `trainX`는 길이 `20`개 단위로 구성되어, 총 `650`개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq05DSyd6DpP"
      },
      "source": [
        "print(trainX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv_LADs2J0FZ"
      },
      "source": [
        "`trainY`의 경우에도 쌍을 이루어 구성되므로, 총 `650`개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wIc12356DpP"
      },
      "source": [
        "print(trainY.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG65IJQ6J_pc"
      },
      "source": [
        "### *간단한 LSTM 모델 학습*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTz4_avr6DpQ"
      },
      "source": [
        "# create and fit the LSTM network\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "model.add(LSTM(32,input_dim=1))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "V9-mGxWc6DpQ"
      },
      "source": [
        "model.fit(trainX, trainY, nb_epoch=10, batch_size=batch_size, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4byOxpPQ6DpQ"
      },
      "source": [
        "trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n",
        "print('Train Score: ', trainScore)\n",
        "testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n",
        "print('Test Score: ', testScore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeT7NQk06DpQ"
      },
      "source": [
        "print(trainX[-1][1:].shape)\n",
        "print()\n",
        "print(trainX[-1][1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8mXWcU_J6DpR"
      },
      "source": [
        "look_ahead = 250\n",
        "trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n",
        "predictions = np.zeros((look_ahead,1))\n",
        "for i in range(look_ahead):\n",
        "    predict = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n",
        "    predictions[i] = predict\n",
        "    trainPredict.append(np.vstack([trainPredict[-1][1:], predict]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4HF1Scn6DpR"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n",
        "plt.plot(np.arange(look_ahead), predictions,'r-.', label=\"prediction\")\n",
        "plt.plot(np.arange(look_ahead), dataset[train_size:(train_size+look_ahead)], label=\"test function\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgpGImtp6DpR"
      },
      "source": [
        "### *Stateful LSTMs*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KFTqQCJ36DpR"
      },
      "source": [
        "look_back = 20\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT5PbAm_6DpR"
      },
      "source": [
        "# create and fit the LSTM network\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "for i in range(10):\n",
        "    print('epochs : %d ' % (i+1) )\n",
        "    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
        "    model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMJSIF9a6DpS"
      },
      "source": [
        "trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n",
        "print('Train Score: ', trainScore)\n",
        "testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n",
        "print('Test Score: ', testScore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lefedAnO6DpS"
      },
      "source": [
        "look_ahead = 250\n",
        "trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n",
        "predictions = np.zeros((look_ahead,1))\n",
        "for i in range(look_ahead):\n",
        "    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n",
        "    predictions[i] = prediction\n",
        "    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcCdQEGC6DpS"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n",
        "plt.plot(np.arange(look_ahead),predictions,'r-.',label=\"prediction\")\n",
        "plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72Xre8jvNou_"
      },
      "source": [
        "### *그 외 참고용 소스코드*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "fMtPBW426DpS"
      },
      "source": [
        "#### Stateful LSTMs with wider window"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "doc9k3cL6DpS"
      },
      "source": [
        "look_back = 40\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aiJimfo6DpS"
      },
      "source": [
        "%%time\n",
        "theano.config.compute_test_value = \"ignore\"\n",
        "# create and fit the LSTM network\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "for i in range(200):\n",
        "    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "    model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYULgw3V6DpT"
      },
      "source": [
        "trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n",
        "print('Train Score: ', trainScore)\n",
        "testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n",
        "print('Test Score: ', testScore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1pG-OC516DpU"
      },
      "source": [
        "look_ahead = 250\n",
        "trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n",
        "predictions = np.zeros((look_ahead,1))\n",
        "for i in range(look_ahead):\n",
        "    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n",
        "    predictions[i] = prediction\n",
        "    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcmAjRhG6DpU"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n",
        "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
        "plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EA1oxOs6DpU"
      },
      "source": [
        "#### Stateful LSTMs, Stacked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qY3UhiB6DpU"
      },
      "source": [
        "%%time\n",
        "theano.config.compute_test_value = \"ignore\"\n",
        "# create and fit the LSTM network\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "for i in range(200):\n",
        "    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "    model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJquKM826DpV"
      },
      "source": [
        "trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n",
        "print('Train Score: ', trainScore)\n",
        "testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n",
        "print('Test Score: ', testScore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hAbUcJ5P6DpV"
      },
      "source": [
        "look_ahead = 250\n",
        "trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n",
        "predictions = np.zeros((look_ahead,1))\n",
        "for i in range(look_ahead):\n",
        "    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n",
        "    predictions[i] = prediction\n",
        "    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXBjrL326DpV"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n",
        "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
        "plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4HsEN3g6DpW"
      },
      "source": [
        "#### Stateful LSTM stacked DEEPER!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxim6tKg6DpW"
      },
      "source": [
        "%%time\n",
        "theano.config.compute_test_value = \"ignore\"\n",
        "# create and fit the LSTM network\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "for i in range(2):\n",
        "    model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "for i in range(200):\n",
        "    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "    model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35EMtaj6DpW"
      },
      "source": [
        "trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n",
        "print('Train Score: ', trainScore)\n",
        "testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n",
        "print('Test Score: ', testScore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ou-M4np26DpW"
      },
      "source": [
        "look_ahead = 250\n",
        "trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n",
        "predictions = np.zeros((look_ahead,1))\n",
        "for i in range(look_ahead):\n",
        "    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n",
        "    predictions[i] = prediction\n",
        "    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1xelE066DpW"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n",
        "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
        "plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcpCUnhm6DpX"
      },
      "source": [
        "#### Normal Deep Learning in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjbZZHxX6DpX"
      },
      "source": [
        "%%time\n",
        "trainX = np.squeeze(trainX)\n",
        "testX = np.squeeze(testX)\n",
        "theano.config.compute_test_value = \"ignore\"\n",
        "# create and fit the LSTM network\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "model.add(Dense(output_dim=32,input_dim=40,activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "for i in range(2):\n",
        "    model.add(Dense(output_dim=32,activation=\"relu\"))\n",
        "    model.add(Dropout(0.3))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adagrad')\n",
        "model.fit(trainX, trainY, nb_epoch=100, batch_size=32, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4FSA5s66DpX"
      },
      "source": [
        "trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n",
        "print('Train Score: ', trainScore)\n",
        "testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n",
        "print('Test Score: ', testScore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF1rUMg06DpX"
      },
      "source": [
        "look_ahead = 250\n",
        "xval = np.hstack([trainX[-1][1:], trainY[-1]])[None,:]\n",
        "predictions = np.zeros((look_ahead,1))\n",
        "for i in range(look_ahead):\n",
        "    prediction = model.predict(xval, batch_size=32)\n",
        "    predictions[i] = prediction\n",
        "    xval = np.hstack([xval[:,1:],prediction])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXPlfRLZ6DpX"
      },
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n",
        "# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n",
        "plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n",
        "plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "S_5C1XZF6DpX"
      },
      "source": [
        "1000개의 샘플이 있다.\n",
        "타임스탬프는 100개이다. 즉 100 순간의 데이터가 있다. 하나의 타임스템프는 10개의 백터 길이가 있다. \n",
        "입력자료는 1000 * 100 * 10 \n",
        "배치사이즈는 20개이다.\n",
        "\n",
        "배치사이즈를 지정하지 않는다면, \n",
        "1000개의 샘플을 모두 취한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GANiwbT36DpX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkv60Ho8CuLL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEOOxhpsCY7G"
      },
      "source": [
        "## **3. LSTM 모델 활용하기**\n",
        "\n",
        "앞서 살펴본 LSTM 레이어를 이용하여 몇가지 순환 신경망 모델을 만들어보고, 각 모델에 \"나비야\" 동요를 학습시켜보면서 자세히 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxoDeCG5CY7H"
      },
      "source": [
        "---\n",
        "\n",
        "### *시퀀스 데이터 준비*\n",
        "\n",
        "순환 신경망은 주로 자연어 처리에 많이 쓰이기 때문에 문장 학습 예제가 일반적이지만 본 강좌에서는 악보 학습을 해보겠습니다. 그 이유는 \n",
        "- 음계가 문장보다 더 코드화 하기 쉽고, \n",
        "- 시계열 자료이며, \n",
        "- 나온 결과를 악보로 볼 수 있으며,\n",
        "- 무엇보다 우리가 학습한 모델이 연주하는 곡을 들어볼 수 있기 때문입니다. \n",
        "일단 쉬운 악보인 '나비야'를 준비했습니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_2.png)\n",
        "\n",
        "음표 밑에 간단한 음표코드를 표시하였습니다. 알파벳은 음계를 나타내며, 숫자는 음의 길이를 나타냅니다.\n",
        "- c(도), d(레), e(미), f(파), g(솔), a(라), b(시)\n",
        "- 4(4분음표), 8(8분음표)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LflhttcQCY7H"
      },
      "source": [
        "---\n",
        "\n",
        "### *데이터셋 생성*\n",
        "\n",
        "먼저 두 마디만 살펴보겠습니다. \n",
        "\n",
        "* g8 e8 e4\n",
        "* f8 d8 d4 \n",
        "\n",
        "여기서 우리가 정의한 문제대로 4개 음표 입력으로 다음 출력 음표를 예측하려면, 아래와 같이 데이터셋을 구성합니다.\n",
        "\n",
        "* g8 e8 e4 f8 **d8** : 1~4번째 음표, **5번째** 음표\n",
        "* e8 e4 f8 d8 **d4** : 2~5번째 음표, **6번째** 음표\n",
        "\n",
        "6개의 음표로는 위와 같이 2개의 샘플이 나옵니다. 각 샘플은 4개의 입력 데이터와 1개의 라벨값으로 구성되어 있습니다. 즉 1~4번째 열은 속성(feature)이고, 5번째 열은 클래스(class)를 나타냅니다. 이렇게 4개씩 구간을 보는 것을 윈도우 크기가 4라고 합니다. 그리고 문자와 숫자로 된 음표(코드)로는 모델 입출력으로 사용할 수 없기 때문에 각 코드를 숫자로 변환할 수 있는 사전을 하나 만들어봅니다. 첫번째 사전은 코드를 숫자로, 두번째 사전은 숫자를 코드로 만드는 코드입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TIcD7y5wCY7I"
      },
      "source": [
        "code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n",
        "            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n",
        "\n",
        "idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n",
        "            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjUaQ_YQCY7K"
      },
      "source": [
        "이러한 사전을 이용해서 순차적인 음표를 우리가 지정한 윈도우 크기만큼 잘라 데이터셋을 생성하는 함수를 정의해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GyjnmpV_CY7K"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def seq2dataset(seq, window_size):\n",
        "    dataset = []\n",
        "    for i in range(len(seq)-window_size):\n",
        "        subset = seq[i:(i+window_size+1)]\n",
        "        dataset.append([code2idx[item] for item in subset])\n",
        "    return np.array(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1tII3ZCY7K"
      },
      "source": [
        "seq라는 변수에 \"나비야\" 곡 전체 음표를 저장한 다음, seq2dataset() 함수를 하여 dataset를 생성합니다. 데이터셋은 앞서 정의한 사전에 따라 숫자로 변환되어 생성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekq7WJAxCY7L"
      },
      "source": [
        "seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n",
        "       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n",
        "       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n",
        "       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n",
        "\n",
        "dataset = seq2dataset(seq, window_size = 4)\n",
        "\n",
        "print(dataset.shape)\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ev89nmsCY7S"
      },
      "source": [
        "---\n",
        "\n",
        "### *학습 과정*\n",
        "\n",
        "\"나비야\"노래는 우리에게 너무나 익숙한 노래입니다. 만약 옆사람이 \"나비야~ 나\"까지만 불러도 나머지를 이어서 다 부를 수 있을 정도로 말이죠. 이렇게 첫 4개 음표를 입력하면 나머지를 연주할 수 있는 모델을 만드는 것이 목표입니다. 우리가 정의한 문제를 풀기 위해 먼저 모델을 학습시켜야 합니다. 학습 시키는 방식은 아래와 같습니다.\n",
        "\n",
        "- 파란색 박스가 입력값이고, 빨간색 박스가 우리가 원하는 출력값입니다. \n",
        "- 1~4번째 음표를 데이터로 5번째 음표를 라벨값으로 학습을 시킵니다.\n",
        "- 다음에는 2~5번째 음표를 데이터로 6번째 음표를 라벨값으로 학습을 시킵니다.\n",
        "- 이후 한 음표씩 넘어가면서 노래 끝까지 학습시킵니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pqvof71a868"
      },
      "source": [
        "---\n",
        "### *예측 과정*\n",
        "\n",
        "예측은 두 가지 방법으로 해보겠습니다. `한 스텝 예측`과 `곡 전체 예측`입니다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkYjwfNma-Gz"
      },
      "source": [
        "#### 한 스텝 예측\n",
        "\n",
        "한 스텝 예측이란 실제 음표 4개를 입력하여 다음 음표 1개를 예측하는 것을 반복하는 것입니다. 이 방법에서는 모델의 입력값으로는 항상 실제 음표가 들어갑니다.\n",
        "- 모델에 t0, t1, t2, t3를 입력하면 y0 출력이 나옵니다. \n",
        "- 모델에 t1, t2, t3, t4를 입력하면 y1 출력이 나옵니다.\n",
        "- 모델에 t2, t3, t4, t5를 입력하면 y2 출력이 나옵니다.\n",
        "- 이 과정을 y49 출력까지 반복합니다. \n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_6.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB6d_3E8CY7T"
      },
      "source": [
        "#### 곡 전체 예측\n",
        "\n",
        "곡 전체 예측이란 입력된 초가 4개 음표만을 입력으로 곡 전체를 예측하는 것입니다. 초반부가 지나면, 예측값만으로 모델에 입력되어 다음 예측값이 나오는 식입니다. 그야말로 \"나비야~ 나\"까지 알려주면 나머지까지 모두 연주를 하는 것이죠. 만약 중간에 틀린 부분이 생긴다면, 이후 음정, 박자는 모두 이상하게 될 가능성이 많습니다. 예측 오류가 누적되는 것이겠죠.\n",
        "\n",
        "- 모델에 t0, t1, t2, t3를 입력하면 y0 출력이 나옵니다.\n",
        "- 예측값인 y0를 t4라고 가정하고, 모델에 t1, t2, t3, t4을 입력하면 y1 출력이 나옵니다.\n",
        "- 예측값인 y1을 t5라고 가정하고, 모델에 t2, t3, t4(예측값), t5(예측값)을 입력하면 y2 출력이 나옵니다.\n",
        "- 이 과정을 y49 출력까지 반복합니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_7.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtPWC0yjCY7T"
      },
      "source": [
        "---\n",
        "\n",
        "### *다층 퍼셉트론 모델*\n",
        "\n",
        "앞서 생성한 데이터셋으로 먼저 다층 퍼셉트론 모델을 학습시켜보겠습니다. Dense 레이어 3개로 구성하였고, 입력 속성이 4개이고 출력이 12개(one_hot_vec_size=12)으로 설정했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii9tcyUTCY7U"
      },
      "source": [
        "one_hot_vec_size = len(code2idx)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=4, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXkQ9fsKCY7U"
      },
      "source": [
        "\"나비야\" 악보를 이 모델을 학습할 경우 다음 그림과 같이 수행됩니다. 4개의 음표를 입력으로 받고, 그 다음 음표가 라벨값으로 지정됩니다. 이 과정을 곡이 마칠 때까지 반복하게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63BvmS0FCY7U"
      },
      "source": [
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_MLP.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfRP2sN5CY7V"
      },
      "source": [
        "#### 소스코드\n",
        "\n",
        "전체 소스는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7cGftucCY7V"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "# 랜덤시드 고정시키기\n",
        "np.random.seed(5)\n",
        "\n",
        "# 손실 이력 클래스 정의\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def init(self):\n",
        "        self.losses = []\n",
        "        \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "\n",
        "# 데이터셋 생성 함수        \n",
        "def seq2dataset(seq, window_size):\n",
        "    dataset = []\n",
        "    for i in range(len(seq)-window_size):\n",
        "        subset = seq[i:(i+window_size+1)]\n",
        "        dataset.append([code2idx[item] for item in subset])\n",
        "    return np.array(dataset)\n",
        "\n",
        "# 1. 데이터 준비하기\n",
        "\n",
        "# 코드 사전 정의\n",
        "\n",
        "code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n",
        "            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n",
        "\n",
        "idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n",
        "            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n",
        "\n",
        "# 시퀀스 데이터 정의\n",
        "\n",
        "seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n",
        "       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n",
        "       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n",
        "       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n",
        "\n",
        "# 2. 데이터셋 생성하기\n",
        "dataset = seq2dataset(seq, window_size = 4)\n",
        "\n",
        "print(dataset.shape)\n",
        "print(dataset)\n",
        "\n",
        "# 입력(X)과 출력(Y) 변수로 분리하기\n",
        "x_train = dataset[:,0:4]\n",
        "y_train = dataset[:,4]\n",
        "\n",
        "max_idx_value = 13\n",
        "\n",
        "# 입력값 정규화 시키기\n",
        "x_train = x_train / float(max_idx_value)\n",
        "\n",
        "# 라벨값에 대한 one-hot 인코딩 수행\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "one_hot_vec_size = y_train.shape[1]\n",
        "\n",
        "print(\"one hot encoding vector size is \", one_hot_vec_size)\n",
        "\n",
        "# 3. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=4, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))\n",
        "\n",
        "# 4. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = LossHistory() # 손실 이력 객체 생성\n",
        "history.init()\n",
        "\n",
        "# 5. 모델 학습시키기\n",
        "model.fit(x_train, y_train, epochs=2000, batch_size=10, verbose=2, callbacks=[history])\n",
        "    \n",
        "# 6. 학습과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# 7. 모델 평가하기\n",
        "scores = model.evaluate(x_train, y_train)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# 8. 모델 사용하기\n",
        "\n",
        "pred_count = 50 # 최대 예측 개수 정의\n",
        "\n",
        "# 한 스텝 예측\n",
        "\n",
        "seq_out = ['g8', 'e8', 'e4', 'f8']\n",
        "pred_out = model.predict(x_train)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    idx = np.argmax(pred_out[i]) # one-hot 인코딩을 인덱스 값으로 변환\n",
        "    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
        "    \n",
        "print(\"one step prediction : \", seq_out)\n",
        "\n",
        "# 곡 전체 예측\n",
        "\n",
        "seq_in = ['g8', 'e8', 'e4', 'f8']\n",
        "seq_out = seq_in\n",
        "seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n",
        "\n",
        "for i in range(pred_count):\n",
        "    sample_in = np.array(seq_in)\n",
        "    sample_in = np.reshape(sample_in, (1, 4)) # batch_size, feature\n",
        "    pred_out = model.predict(sample_in)\n",
        "    idx = np.argmax(pred_out)\n",
        "    seq_out.append(idx2code[idx])\n",
        "    seq_in.append(idx / float(max_idx_value))\n",
        "    seq_in.pop(0)\n",
        "\n",
        "print(\"full song prediction : \", seq_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7H_l6WqCY7X"
      },
      "source": [
        "한 스텝 예측 결과와 곡 전체 예측 결과를 악보로 그려보았습니다. 이 중 틀린 부분을 빨간색 박스로 표시해봤습니다. 총 50개 예측 중 4개가 틀려서 92%의 정확도가 나왔습니다. 중간에 틀린 부분이 생기면 곡 전체를 예측하는 데 있어서는 그리 좋은 성능이 나오지 않습니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_MLP_song.png)\n",
        "\n",
        "위 악보로 연주한 곡은 아래 링크에서 다운로드 받으실 수 있습니다.\n",
        "\n",
        "* [http://tykimos.github.io/warehouse/2017-4-9-MLP_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-MLP_one_step_prediction.mp3)\n",
        "* [http://tykimos.github.io/warehouse/2017-4-9-MLP_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-MLP_full_song_prediction.mp3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1BCtlleCY7Y"
      },
      "source": [
        "---\n",
        "\n",
        "### *기본 LSTM 모델*\n",
        "\n",
        "이번에는 간단한 기본 LSTM 모델로 먼저 테스트를 해보겠습니다. 모델 구성은 다음과 같이 하였습니다.\n",
        "- 128 메모리 셀을 가진 LSTM 레이어 1개와 Dense 레이어로 구성\n",
        "- 입력은 샘플이 50개, 타임스텝이 4개, 속성이 1개로 구성\n",
        "- 상태유지(stateful) 모드 비활성화\n",
        "\n",
        "케라스에서는 아래와 같이 LSTM을 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "UcWxY1whCY7Z"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (4, 1)))\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pVDR15RCY7Z"
      },
      "source": [
        "LSTM을 제대로 활용하기 위해서는 `상태유지 모드`, `배치사이즈`, `타임스텝`, `속성`에 대한 개념에 이해가 필요합니다. 본 절에서는 `타임스텝`에 대해서 먼저 알아보겠습니다. `타임스텝`이란 하나의 샘플에 포함된 시퀀스 개수입니다. 이는 앞서 살펴본 \"input_length\"와 동일합니다. 현재 문제에서는 매 샘플마다 4개의 값을 입력하므로 타임스텝이 4개로 지정할 수 있습니다. 즉 윈도우 크기와 동일하게 타임스텝으로 설정하면 됩니다. `속성`에 대해서는 나중에 알아보겠지만, 입력되는 음표 1개당 하나의 인덱스 값을 입력하므로 속성이 1개입니다. 나중에 이 `속성`의 개수를 다르게 해서 테스트 해보겠습니다. 인자로 \"input_shape = (4, 1)'과 \"input_dim = 1, input_length = 4\"는 동일합니다. 설정한 LSTM 모델에 따라 입력할 데이터셋도 샘플 수, 타임스텝 수, 속성 수 형식으로 맞추어야 합니다. 따라서 앞서 구성한 x_train를 아래와 같이 형식을 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "VAz-8PiUCY7a"
      },
      "source": [
        "x_train = np.reshape(x_train, (50, 4, 1)) # 샘플 수, 타임스텝 수, 속성 수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B11VhWLBCY7a"
      },
      "source": [
        "이 모델로 악보를 학습할 경우, 다층 퍼셉트론 모델과 동일하게 4개의 음표를 입력으로 받고, 그 다음 음표가 라벨값으로 지정됩니다. 이 과정을 곡이 마칠 때까지 반복하게 됩니다. 다층 퍼셉트론 모델과 차이점이 있다면, 다층 퍼셉트론 모델에서는 4개의 음표가 4개의 속성으로 입력되고, LSTM에서는 4개의 음표가 4개의 시퀀스 입력으로 들어갑니다. 여기서 속성은 1개입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtZV5CQVCY7b"
      },
      "source": [
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_LSTM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1LT7ckDCY7b"
      },
      "source": [
        "#### 소스코드\n",
        "\n",
        "전체 소스는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-cCGrsECY7c"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# 랜덤시드 고정시키기\n",
        "np.random.seed(5)\n",
        "\n",
        "# 손실 이력 클래스 정의\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def init(self):\n",
        "        self.losses = []\n",
        "        \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "\n",
        "# 데이터셋 생성 함수\n",
        "def seq2dataset(seq, window_size):\n",
        "    dataset = []\n",
        "    for i in range(len(seq)-window_size):\n",
        "        subset = seq[i:(i+window_size+1)]\n",
        "        dataset.append([code2idx[item] for item in subset])\n",
        "    return np.array(dataset)\n",
        "\n",
        "# 1. 데이터 준비하기\n",
        "        \n",
        "# 코드 사전 정의\n",
        "\n",
        "code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n",
        "            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n",
        "\n",
        "idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n",
        "            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n",
        "\n",
        "# 시퀀스 데이터 정의\n",
        "\n",
        "seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n",
        "       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n",
        "       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n",
        "       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n",
        "\n",
        "# 2. 데이터셋 생성하기\n",
        "\n",
        "dataset = seq2dataset(seq, window_size = 4)\n",
        "\n",
        "print(dataset.shape)\n",
        "\n",
        "# 입력(X)과 출력(Y) 변수로 분리하기\n",
        "x_train = dataset[:,0:4]\n",
        "y_train = dataset[:,4]\n",
        "\n",
        "max_idx_value = 13\n",
        "\n",
        "# 입력값 정규화 시키기\n",
        "x_train = x_train / float(max_idx_value)\n",
        "\n",
        "# 입력을 (샘플 수, 타입스텝, 특성 수)로 형태 변환\n",
        "x_train = np.reshape(x_train, (50, 4, 1))\n",
        "\n",
        "# 라벨값에 대한 one-hot 인코딩 수행\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "one_hot_vec_size = y_train.shape[1]\n",
        "\n",
        "print(\"one hot encoding vector size is \", one_hot_vec_size)\n",
        "\n",
        "# 3. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (4, 1)))\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))\n",
        "\n",
        "# 4. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = LossHistory() # 손실 이력 객체 생성\n",
        "history.init()\n",
        "\n",
        "# 5. 모델 학습시키기\n",
        "model.fit(x_train, y_train, epochs=2000, batch_size=14, verbose=2, callbacks=[history])\n",
        "\n",
        "# 6. 학습과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# 7. 모델 평가하기\n",
        "scores = model.evaluate(x_train, y_train)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# 8. 모델 사용하기\n",
        "\n",
        "pred_count = 50 # 최대 예측 개수 정의\n",
        "\n",
        "# 한 스텝 예측\n",
        "\n",
        "seq_out = ['g8', 'e8', 'e4', 'f8']\n",
        "pred_out = model.predict(x_train)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    idx = np.argmax(pred_out[i]) # one-hot 인코딩을 인덱스 값으로 변환\n",
        "    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
        "    \n",
        "print(\"one step prediction : \", seq_out)\n",
        "\n",
        "# 곡 전체 예측\n",
        "\n",
        "seq_in = ['g8', 'e8', 'e4', 'f8']\n",
        "seq_out = seq_in\n",
        "seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n",
        "\n",
        "for i in range(pred_count):\n",
        "    sample_in = np.array(seq_in)\n",
        "    sample_in = np.reshape(sample_in, (1, 4, 1)) # 샘플 수, 타입스텝 수, 속성 수\n",
        "    pred_out = model.predict(sample_in)\n",
        "    idx = np.argmax(pred_out)\n",
        "    seq_out.append(idx2code[idx])\n",
        "    seq_in.append(idx / float(max_idx_value))\n",
        "    seq_in.pop(0)\n",
        "\n",
        "print(\"full song prediction : \", seq_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8ZGpgd4CY7j"
      },
      "source": [
        "한 스텝 예측 결과와 곡 전체 예측 결과를 악보로 그려보았습니다. 이 중 틀린 부분을 빨간색 박스로 표시해봤습니다. 총 50개 예측 중 4개가 틀려서 92%의 정확도가 나왔습니다. 중간에 틀릭 부분이 생기면 곡 전체를 예측하는 데 있어서는 그리 좋은 성능이 나오지 않습니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM_song.png)\n",
        "\n",
        "위 악보로 연주한 곡은 아래 링크에서 다운로드 받으실 수 있습니다.\n",
        "\n",
        "* [http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_one_step_prediction.mp3)\n",
        "* [http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_full_song_prediction.mp3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E99p3YwqCY7j"
      },
      "source": [
        "---\n",
        "\n",
        "### *상태유지 LSTM 모델*\n",
        "\n",
        "이번에는 상태유지(Stateful) LSTM 모델에 대해서 알아보겠습니다. 여기서 `상태유지`라는 것은 현재 학습된 상태가 다음 학습 시 초기 상태로 전달된다는 것을 의미합니다. \n",
        "\n",
        "    상태유지 모드에서는 현재 샘플의 학습 상태가 다음 샘플의 초기 상태로 전달된다.\n",
        "    \n",
        "긴 시퀀드 데이터를 처리할 때, LSTM 모델은 상태유지 모드에서 그 진가를 발휘합니다. 긴 시퀀스 데이터를 샘플 단위로 잘라서 학습하더라도 LSTM 내부적으로 기억할 것은 기억하고 버릴 것은 버려서 기억해야할 중요한 정보만 이어갈 수 있도록 상태가 유지되기 때문입니다. 상태유지 LSTM 모델을 생성하기 위해서는 LSTM 레이어 생성 시, stateful=True로 설정하면 됩니다. 또한 상태유지 모드에서는 입력형태를 batch_input_shape = (배치사이즈, 타임스텝, 속성)으로 설정해야 합니다. 상태유지 모드에서 배치사이즈 개념은 조금 어려우므로 다음 장에서 다루기로 하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LU3Sa098CY7k"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, batch_input_shape = (1, 4, 1), stateful=True))\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGMRGhiPCY7k"
      },
      "source": [
        "상태유지 모드에서는 모델 학습 시에 `상태 초기화`에 대한 고민이 필요합니다. 현재 샘플 학습 상태가 다음 샘플 학습의 초기상태로 전달되는 식인데, 현재 샘플과 다음 샘플 간의 순차적인 관계가 없을 경우에는 상태가 유지되지 않고 초기화가 되어야 합니다. 다음 상황이 이러한 경우에 해당됩니다.\n",
        "\n",
        "- 마지막 샘플 학습이 마치고, 새로운 에포크 수행 시에는 새로운 샘플 학습을 해야하므로 상태 초기화 필요\n",
        "- 한 에포크 안에 여러 시퀀스 데이터 세트가 있을 경우, 새로운 시퀀스 데이터 세트를 학습 전에 상태 초기화 필요\n",
        "\n",
        "현재 코드에서는 한 곡을 가지고 계속 학습을 시키고 있으므로 새로운 에포크 시작 시에만 상태 초기화를 수행하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xIIS-eBxCY7k"
      },
      "source": [
        "num_epochs = 2000\n",
        "\n",
        "for epoch_idx in range(num_epochs):\n",
        "    print ('epochs : ' + str(epoch_idx) )\n",
        "    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False) # 50 is X.shape[0]\n",
        "    model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4eACKLGCY7k"
      },
      "source": [
        "아래 그림은 이 모델로 악보를 학습할 경우를 나타낸 것입니다. 거의 기본 LSTM 모델과 동일하지만 학습된 상태가 다음 샘플 학습 시에 초기 상태로 입력되는 것을 보실 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hdOKBX6CY7k"
      },
      "source": [
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_stateful_LSTM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk_EQS1vCY7l"
      },
      "source": [
        "#### 소스코드\n",
        "\n",
        "전체 소스는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9dXUXO1CY7l"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# 랜덤시드 고정시키기\n",
        "np.random.seed(5)\n",
        "\n",
        "# 손실 이력 클래스 정의\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def init(self):\n",
        "        self.losses = []\n",
        "        \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "\n",
        "# 데이터셋 생성 함수\n",
        "def seq2dataset(seq, window_size):\n",
        "    dataset = []\n",
        "    for i in range(len(seq)-window_size):\n",
        "        subset = seq[i:(i+window_size+1)]\n",
        "        dataset.append([code2idx[item] for item in subset])\n",
        "    return np.array(dataset)        \n",
        "\n",
        "# 1. 데이터 준비하기\n",
        "\n",
        "# 코드 사전 정의\n",
        "\n",
        "code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n",
        "            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n",
        "\n",
        "idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n",
        "            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n",
        "\n",
        "# 시퀀스 데이터 정의\n",
        "\n",
        "seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n",
        "       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n",
        "       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n",
        "       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n",
        "\n",
        "# 2. 데이터셋 생성하기\n",
        "\n",
        "dataset = seq2dataset(seq, window_size = 4)\n",
        "\n",
        "print(dataset.shape)\n",
        "\n",
        "# 입력(X)과 출력(Y) 변수로 분리하기\n",
        "x_train = dataset[:,0:4]\n",
        "y_train = dataset[:,4]\n",
        "\n",
        "max_idx_value = 13\n",
        "\n",
        "# 입력값 정규화 시키기\n",
        "x_train = x_train / float(max_idx_value)\n",
        "\n",
        "# 입력을 (샘플 수, 타임스텝, 특성 수)로 형태 변환\n",
        "x_train = np.reshape(x_train, (50, 4, 1))\n",
        "\n",
        "# 라벨값에 대한 one-hot 인코딩 수행\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "one_hot_vec_size = y_train.shape[1]\n",
        "\n",
        "print(\"one hot encoding vector size is \", one_hot_vec_size)\n",
        "\n",
        "# 3. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, batch_input_shape = (1, 4, 1), stateful=True))\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))\n",
        "    \n",
        "# 4. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 5. 모델 학습시키기\n",
        "num_epochs = 2000\n",
        "\n",
        "history = LossHistory() # 손실 이력 객체 생성\n",
        "\n",
        "history.init()\n",
        "\n",
        "for epoch_idx in range(num_epochs):\n",
        "    print ('epochs : ' + str(epoch_idx) )\n",
        "    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False, callbacks=[history]) # 50 is X.shape[0]\n",
        "    model.reset_states()\n",
        "    \n",
        "# 6. 학습과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# 7. 모델 평가하기\n",
        "scores = model.evaluate(x_train, y_train, batch_size=1)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
        "model.reset_states()\n",
        "\n",
        "# 8. 모델 사용하기\n",
        "\n",
        "pred_count = 50 # 최대 예측 개수 정의\n",
        "\n",
        "# 한 스텝 예측\n",
        "\n",
        "seq_out = ['g8', 'e8', 'e4', 'f8']\n",
        "pred_out = model.predict(x_train, batch_size=1)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    idx = np.argmax(pred_out[i]) # one-hot 인코딩을 인덱스 값으로 변환\n",
        "    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
        "\n",
        "model.reset_states()\n",
        "    \n",
        "print(\"one step prediction : \", seq_out)\n",
        "\n",
        "# 곡 전체 예측\n",
        "\n",
        "seq_in = ['g8', 'e8', 'e4', 'f8']\n",
        "seq_out = seq_in\n",
        "seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n",
        "\n",
        "for i in range(pred_count):\n",
        "    sample_in = np.array(seq_in)\n",
        "    sample_in = np.reshape(sample_in, (1, 4, 1)) # 샘플 수, 타입스텝 수, 속성 수\n",
        "    pred_out = model.predict(sample_in)\n",
        "    idx = np.argmax(pred_out)\n",
        "    seq_out.append(idx2code[idx])\n",
        "    seq_in.append(idx / float(max_idx_value))\n",
        "    seq_in.pop(0)\n",
        "\n",
        "model.reset_states()\n",
        "    \n",
        "print(\"full song prediction : \", seq_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiy1P4VdCY7m"
      },
      "source": [
        "한 스텝 예측 결과와 곡 전체 예측 결과를 악보로 그려보았습니다. Stateful LSTM은 음표를 모두 맞추어서, 전체 곡 예측도 정확하게 했습니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_Stateful_LSTM_song.png)\n",
        "\n",
        "위 악보로 연주한 곡은 아래 링크에서 다운로드 받으실 수 있습니다.\n",
        "\n",
        "* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_one_step_prediction.mp3)\n",
        "* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_full_song_prediction.mp3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xvIG0TrCY7m"
      },
      "source": [
        "### *입력 속성이 여러 개인 모델 구성*\n",
        "\n",
        "입력 속성이 여러 개인 경우에 대해서 알아보겠습니다. 예를 들어 '기온'라는 것을 예측하기 위해서 입력으로 '기온'뿐만아니라 '습도', '기압', '풍향', '풍속' 등 다양한 속성이 있을 수 있습니다. 상태유지 LSTM 모델에서 입력형태를 batch_input_shape = (배치사이즈, 타임스텝, 속성)으로 설정하는데, 마지막 인자를 통해 속성의 개수를 지정할 수 있습니다. '나비야' 예제에서는 현재 입력값이 'c4, e4, g8'등으로 되어 있는 데, 이를 음정과 음길이로 나누어서 2개의 속성으로 입력해보겠습니다. 즉 'c4'는 '(c, 4)'로 나누어서 입력하게 되는 것입니다. 이를 위해 데이터셋 만드는 함수를 아래와 같이 수정하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jG3POYl9CY7m"
      },
      "source": [
        "def code2features(code):\n",
        "    features = []\n",
        "    features.append(code2scale[code[0]]/float(max_scale_value))\n",
        "    features.append(code2length[code[1]])\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJeI8YJGCY7m"
      },
      "source": [
        "LSTM 모델 생성 시 batch_input_shape 인자의 마지막 값이 '1'에서 '2'로 수정되었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Fjg9H4dbCY7n"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, batch_input_shape = (1, 4, 2), stateful=True))\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3A0Jst0CY7n"
      },
      "source": [
        "아래 그림을 보시면 입력이 두 개로 나누어짐을 보실 수 있습니다. 이 방식은 'c8'이니 'd4'처럼 코드 자체를 학습하는 것이 아니라 음정과 음길이를 나누어서 학습하는 효과를 볼 수 있습니다. 사람이 악보를 읽을 때도 이 둘은 나누어서 인지를 하니 좀 더 사람에 가까운 학습이라고 보실 수 있습니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_stateful_LSTM_features.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGa-foECdLYA"
      },
      "source": [
        "#### 소스코드\n",
        "\n",
        "전체 소스는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoX5sMJcCY7n"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# 랜덤시드 고정시키기\n",
        "np.random.seed(5)\n",
        "\n",
        "# 손실 이력 클래스 정의\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def init(self):\n",
        "        self.losses = []\n",
        "        \n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "\n",
        "# 데이터셋 생성 함수\n",
        "def seq2dataset(seq, window_size):\n",
        "    dataset_X = []\n",
        "    dataset_Y = []\n",
        "    \n",
        "    for i in range(len(seq)-window_size):\n",
        "        \n",
        "        subset = seq[i:(i+window_size+1)]\n",
        "        \n",
        "        for si in range(len(subset)-1):\n",
        "            features = code2features(subset[si])            \n",
        "            dataset_X.append(features)\n",
        "\n",
        "        dataset_Y.append([code2idx[subset[window_size]]])\n",
        "        \n",
        "    return np.array(dataset_X), np.array(dataset_Y)\n",
        "\n",
        "# 속성 변환 함수\n",
        "def code2features(code):\n",
        "    features = []\n",
        "    features.append(code2scale[code[0]]/float(max_scale_value))\n",
        "    features.append(code2length[code[1]])\n",
        "    return features\n",
        "\n",
        "# 1. 데이터 준비하기\n",
        "\n",
        "# 코드 사전 정의\n",
        "\n",
        "code2scale = {'c':0, 'd':1, 'e':2, 'f':3, 'g':4, 'a':5, 'b':6}\n",
        "code2length = {'4':0, '8':1}\n",
        "\n",
        "code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n",
        "            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n",
        "\n",
        "idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n",
        "            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n",
        "\n",
        "max_scale_value = 6.0\n",
        "    \n",
        "# 시퀀스 데이터 정의\n",
        "seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n",
        "       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n",
        "       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n",
        "       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n",
        "\n",
        "# 2. 데이터셋 생성하기\n",
        "\n",
        "x_train, y_train = seq2dataset(seq, window_size = 4)\n",
        "\n",
        "# 입력을 (샘플 수, 타임스텝, 특성 수)로 형태 변환\n",
        "x_train = np.reshape(x_train, (50, 4, 2))\n",
        "\n",
        "# 라벨값에 대한 one-hot 인코딩 수행\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "one_hot_vec_size = y_train.shape[1]\n",
        "\n",
        "print(\"one hot encoding vector size is \", one_hot_vec_size)\n",
        "\n",
        "# 3. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, batch_input_shape = (1, 4, 2), stateful=True))\n",
        "model.add(Dense(one_hot_vec_size, activation='softmax'))\n",
        "    \n",
        "# 4. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 5. 모델 학습시키기\n",
        "num_epochs = 2000\n",
        "\n",
        "history = LossHistory() # 손실 이력 객체 생성\n",
        "history.init()\n",
        "\n",
        "for epoch_idx in range(num_epochs):\n",
        "    print ('epochs : ' + str(epoch_idx) )\n",
        "    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False, callbacks=[history]) # 50 is X.shape[0]\n",
        "    model.reset_states()\n",
        "    \n",
        "# 6. 학습과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# 7. 모델 평가하기\n",
        "scores = model.evaluate(x_train, y_train, batch_size=1)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
        "model.reset_states()\n",
        "\n",
        "# 8. 모델 사용하기\n",
        "\n",
        "pred_count = 50 # 최대 예측 개수 정의\n",
        "\n",
        "# 한 스텝 예측\n",
        "\n",
        "seq_out = ['g8', 'e8', 'e4', 'f8']\n",
        "pred_out = model.predict(x_train, batch_size=1)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    idx = np.argmax(pred_out[i]) # one-hot 인코딩을 인덱스 값으로 변환\n",
        "    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
        "    \n",
        "print(\"one step prediction : \", seq_out)\n",
        "\n",
        "model.reset_states()\n",
        "\n",
        "# 곡 전체 예측\n",
        "\n",
        "seq_in = ['g8', 'e8', 'e4', 'f8']\n",
        "seq_out = seq_in\n",
        "\n",
        "seq_in_featrues = []\n",
        "\n",
        "for si in seq_in:\n",
        "    features = code2features(si)\n",
        "    seq_in_featrues.append(features)\n",
        "\n",
        "for i in range(pred_count):\n",
        "    sample_in = np.array(seq_in_featrues)\n",
        "    sample_in = np.reshape(sample_in, (1, 4, 2)) # 샘플 수, 타입스텝 수, 속성 수\n",
        "    pred_out = model.predict(sample_in)\n",
        "    idx = np.argmax(pred_out)\n",
        "    seq_out.append(idx2code[idx])\n",
        "    \n",
        "    features = code2features(idx2code[idx])\n",
        "    seq_in_featrues.append(features)\n",
        "    seq_in_featrues.pop(0)\n",
        "\n",
        "model.reset_states()\n",
        "    \n",
        "print(\"full song prediction : \", seq_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HqOvKNCY7o"
      },
      "source": [
        "수행결과는 곡 전체를 정확하게 예측을 했습니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_Stateful_LSTM_features_song.png)\n",
        "\n",
        "위 악보로 연주한 곡은 아래 링크에서 다운로드 받으실 수 있습니다.\n",
        "\n",
        "* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_one_step_prediction.mp3)\n",
        "* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_full_song_prediction.mp3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtEzRcZNCY7o"
      },
      "source": [
        "---\n",
        "\n",
        "### 요약\n",
        "\n",
        "익숙한 노래인 \"나비야\"를 가지고 순한 신경망 모델에 학습시켜봤습니다. 순항 신경망 모델 중 가장 많이 사용되는 LSTM 모델에 대해서 알아보고, 주요 인자들이 어떤 특성을 가지고 있는 지도 살펴보았습니다. 앞서 살펴본 4가지 모델에 대해서 학습 손실값을 그래프로 표시해봤습니다. 다층퍼셉트론 모델 > 기본 LSTM 모델 > 상태유지 LSTM 모델 (1개 속성) > 상태유지 LSTM 모델 (2개 속성) 순으로 더 빨리 학습되는 것을 확인할 수 있습니다.\n",
        "\n",
        "![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_loss_history.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssWFM2i0CuH4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Slhf2tq6ar"
      },
      "source": [
        "## **Lab 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItLEd6uBq993"
      },
      "source": [
        "다른 노래를 이용해서, 3장에서와 같은 방식으로 <u>악보를 예측하는 모델</u>을 학습하고, 출력 결과로부터 성능을 확인합니다.\n",
        "\n",
        "*   순환 신경망 모델의 레이어 또는 파라미터를 자유롭게 조절\n",
        "*   또는, 사전 데이터를 참조하는 윈도우 범위<small>(e.g., 예제에서 20개 보고 예측)</small> 등을 자유롭게 조절\n",
        "\n",
        "실습코드의 결과를 초과하여 성능이 향상되는 구성을 만들어보고, 출력 결과를 확인합니다.\n",
        "\n",
        "**※ 제출방법:** 실습내용 및 출력 결과가 저장된 Colab 파일(`*.ipynb`)를 KLMS의 과제 항목에 업로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhCTUS0trvK0"
      },
      "source": [
        "### **<small>(참고)</small> 악보 시각화 툴 설치**\n",
        "\n",
        "*   Abjad 공식 홈페이지: https://abjad.github.io/\n",
        "  - Documantation:  http://abjad.mbrsi.org/index.html\n",
        "*   LilyPond 공식 홈페이지: http://lilypond.org/development.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ziwx8ztxsMav"
      },
      "source": [
        "#### *Abjad 파이썬 모듈 설치*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tMj66Ubedap"
      },
      "source": [
        "!pip install abjad[development,ipython]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FCOWV4sO3u"
      },
      "source": [
        "#### *LilyPond 리눅스 라이브러리 설치*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Io9ckZfkAE"
      },
      "source": [
        "# 설치 스크립트 다운로드\n",
        "!wget https://lilypond.org/download/binaries/linux-64/lilypond-2.22.0-1.linux-64.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30x1o0AffxJ1"
      },
      "source": [
        "# 스크립트 실행 후, 출력 콘솔에서 Enter 입력하여 설치 진행\n",
        "!sh lilypond-2.22.0-1.linux-64.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEvgUenniCft"
      },
      "source": [
        "# 정상 설치여부 확인\n",
        "!lilypond --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIob8LGJjAj5"
      },
      "source": [
        "# 위 버전 확인 단계에서, \n",
        "#   특정 라이브러리가 없다고 하는 경우, 문제해결을 위해 심볼릭 링크 재생성\n",
        "!rm /usr/local/lilypond/usr/lib/libstdc++.so.6 \n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /usr/local/lilypond/usr/lib/libstdc++.so.6 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui4WCr7Ysx81"
      },
      "source": [
        "#### *악보출력 기능 확인*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih3KzZVypmIs"
      },
      "source": [
        "%load_ext abjadext.ipython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpwK4C3eZGu"
      },
      "source": [
        "import abjad\n",
        "seq = \"c'16 f' g' a' d' g' a' b' e' a' b' c'' f' b' c'' d''16\"\n",
        "voice_1 = abjad.Voice(seq, name=\"Voice_1\")\n",
        "staff_1 = abjad.Staff([voice_1], name=\"Staff_1\")\n",
        "abjad.show(staff_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDt09hNjtEEp"
      },
      "source": [
        "### **신규 악보 및 코드 작성영역**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSLHaQsiwrGp"
      },
      "source": [
        "#### *신규 악보: 비행기 (동요)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzbRwfthte3k"
      },
      "source": [
        "seq_lab2 = \"e'8. d'16 c'8 d'8 e'8 e'8 e'4\"\\\n",
        "            + \" d'8 d'8 d' e'8 e'8 e'\"\\\n",
        "            + \" e'8. d'16 c'8 d'8 e'8 e'8 e'\"\\\n",
        "            + \" d'8 d'8 e'8. d'16 c'1\"\n",
        "\n",
        "voice_1 = abjad.Voice(seq_lab2, name=\"Voice_1\")\n",
        "staff_1 = abjad.Staff([voice_1], name=\"Staff_1\")\n",
        "abjad.show(staff_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Hdg5Caw2AT"
      },
      "source": [
        "#### *코드 작성영역*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVYEYS15wpi6"
      },
      "source": [
        "######\n",
        "## 3장 내용을 참조해서 Lab2를 작성하세요.\n",
        "######\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}